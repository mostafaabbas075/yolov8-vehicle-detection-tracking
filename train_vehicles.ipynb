{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-03T00:27:22.492378Z",
     "iopub.status.busy": "2025-05-03T00:27:22.492177Z",
     "iopub.status.idle": "2025-05-03T00:27:24.718216Z",
     "shell.execute_reply": "2025-05-03T00:27:24.717041Z",
     "shell.execute_reply.started": "2025-05-03T00:27:22.492361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_330/1229163428.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.718648Z",
     "iopub.status.idle": "2025-05-03T00:27:24.718846Z",
     "shell.execute_reply": "2025-05-03T00:27:24.718756Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.718747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.719565Z",
     "iopub.status.idle": "2025-05-03T00:27:24.719769Z",
     "shell.execute_reply": "2025-05-03T00:27:24.719681Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.719671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configure logging to suppress per-image output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatasetCleaner:\n",
    "    \"\"\"Cleans the dataset by removing duplicate and corrupted images along with their labels.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_img_dir='/kaggle/input/detection-cars/images_cars', \n",
    "                 input_label_dir='/kaggle/input/detection-cars/labels_cars', \n",
    "                 output_dir='/kaggle/working/detection-cars-cleaned'):\n",
    "        self.input_img_dir = Path(input_img_dir)\n",
    "        self.input_label_dir = Path(input_label_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_img_dir = self.output_dir / 'images_cars'\n",
    "        self.output_label_dir = self.output_dir / 'labels_cars'\n",
    "        self.duplicates = []\n",
    "        self.corrupted = []\n",
    "        \n",
    "    def copy_dataset(self):\n",
    "        \"\"\"Copy the dataset to the output directory.\"\"\"\n",
    "        logger.info(\"Copying dataset to output directory...\")\n",
    "        print(\"INFO: Copying dataset to output directory...\")\n",
    "        self.output_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy images\n",
    "        for img_file in self.input_img_dir.glob('*.jpg'):\n",
    "            shutil.copy(img_file, self.output_img_dir / img_file.name)\n",
    "        \n",
    "        # Copy labels\n",
    "        for label_file in self.input_label_dir.glob('*.txt'):\n",
    "            shutil.copy(label_file, self.output_label_dir / label_file.name)\n",
    "        \n",
    "        logger.info(\"Dataset copied successfully.\")\n",
    "        print(\"INFO: Dataset copied successfully.\")\n",
    "    \n",
    "    def compute_image_hash(self, img_path):\n",
    "        \"\"\"Compute SHA256 hash of an image for duplicate detection.\"\"\"\n",
    "        try:\n",
    "            with open(img_path, 'rb') as f:\n",
    "                return hashlib.sha256(f.read()).hexdigest()\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def is_valid_image(self, img_path):\n",
    "        \"\"\"Check if an image is valid and not corrupted.\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None or np.all(img == 0) or np.all(img == 255):\n",
    "                return False\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def find_duplicates(self):\n",
    "        \"\"\"Find duplicate images based on content hash.\"\"\"\n",
    "        hashes = {}\n",
    "        for img_file in self.output_img_dir.glob('*.jpg'):\n",
    "            img_hash = self.compute_image_hash(img_file)\n",
    "            if img_hash:\n",
    "                if img_hash in hashes:\n",
    "                    self.duplicates.append(img_file)\n",
    "                else:\n",
    "                    hashes[img_hash] = img_file\n",
    "    \n",
    "    def find_corrupted(self):\n",
    "        \"\"\"Find corrupted images.\"\"\"\n",
    "        for img_file in self.output_img_dir.glob('*.jpg'):\n",
    "            if not self.is_valid_image(img_file):\n",
    "                self.corrupted.append(img_file)\n",
    "    \n",
    "    def remove_files(self, files, file_type):\n",
    "        \"\"\"Remove images and their corresponding labels.\"\"\"\n",
    "        removed_count = 0\n",
    "        for file in files:\n",
    "            label_file = self.output_label_dir / f'{file.stem}.txt'\n",
    "            try:\n",
    "                if file.exists():\n",
    "                    file.unlink()\n",
    "                    removed_count += 1\n",
    "                if label_file.exists():\n",
    "                    label_file.unlink()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to remove {file_type} file {file} or its label: {e}\")\n",
    "                print(f\"WARNING: Failed to remove {file_type} file {file} or its label: {e}\")\n",
    "        return removed_count\n",
    "    \n",
    "    def clean(self):\n",
    "        \"\"\"Clean the dataset by removing duplicates and corrupted images.\"\"\"\n",
    "        # Step 1: Copy dataset\n",
    "        self.copy_dataset()\n",
    "        \n",
    "        # Step 2: Find duplicates\n",
    "        logger.info(\"Checking for duplicate images...\")\n",
    "        print(\"INFO: Checking for duplicate images...\")\n",
    "        self.find_duplicates()\n",
    "        duplicate_count = len(self.duplicates)\n",
    "        \n",
    "        # Step 3: Find corrupted images\n",
    "        logger.info(\"Checking for corrupted images...\")\n",
    "        print(\"INFO: Checking for corrupted images...\")\n",
    "        self.find_corrupted()\n",
    "        corrupted_count = len(self.corrupted)\n",
    "        \n",
    "        # Step 4: Handle corrupted images\n",
    "        removed_corrupted = 0\n",
    "        if corrupted_count > 0:\n",
    "            print(f\"INFO: Found {corrupted_count} corrupted images.\")\n",
    "            response = input(\"Do you want to remove corrupted images and their labels? (y/n): \").strip().lower()\n",
    "            if response == 'y':\n",
    "                removed_corrupted = self.remove_files(self.corrupted, \"corrupted\")\n",
    "            else:\n",
    "                print(\"INFO: Corrupted images will not be removed.\")\n",
    "        \n",
    "        # Step 5: Remove duplicates\n",
    "        removed_duplicates = self.remove_files(self.duplicates, \"duplicate\")\n",
    "        \n",
    "        # Step 6: Generate report\n",
    "        total_images = len(list(self.output_img_dir.glob('*.jpg')))\n",
    "        total_labels = len(list(self.output_label_dir.glob('*.txt')))\n",
    "        report = (\n",
    "            f\"Cleaning Report:\\n\"\n",
    "            f\"- Total images after cleaning: {total_images}\\n\"\n",
    "            f\"- Total labels after cleaning: {total_labels}\\n\"\n",
    "            f\"- Duplicate images found and removed: {removed_duplicates}\\n\"\n",
    "            f\"- Corrupted images found: {corrupted_count}\\n\"\n",
    "            f\"- Corrupted images removed: {removed_corrupted}\\n\"\n",
    "        )\n",
    "        logger.info(report)\n",
    "        print(f\"INFO: {report}\")\n",
    "        \n",
    "        # Save report to file\n",
    "        with open(self.output_dir / 'cleaning_report.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "        print(f\"INFO: Report saved to {self.output_dir / 'cleaning_report.txt'}\")\n",
    "\n",
    "def main():\n",
    "    cleaner = DatasetCleaner()\n",
    "    cleaner.clean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.721522Z",
     "iopub.status.idle": "2025-05-03T00:27:24.721828Z",
     "shell.execute_reply": "2025-05-03T00:27:24.721687Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.721672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import osw\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def check_labels(label_dir='/kaggle/input/detection-cars/labels_cars',\n",
    "                 image_dir='/kaggle/input/detection-cars/images_cars',\n",
    "                 output_dir='/kaggle/working/detection-cars-cleaned'):\n",
    "    \"\"\"Check label files for valid class IDs (0-3), copy valid files to output_dir, remove invalid labels and corresponding images.\"\"\"\n",
    "    label_dir = Path(label_dir)\n",
    "    image_dir = Path(image_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Check if input directories exist\n",
    "    if not label_dir.exists():\n",
    "        logging.error(f\"Label directory {label_dir} does not exist\")\n",
    "        print(f\"ERROR: Label directory {label_dir} does not exist\")\n",
    "        return\n",
    "    if not image_dir.exists():\n",
    "        logging.error(f\"Image directory {image_dir} does not exist\")\n",
    "        print(f\"ERROR: Image directory {image_dir} does not exist\")\n",
    "        return\n",
    "    \n",
    "    # Create output directories\n",
    "    output_image_dir = output_dir / 'images'\n",
    "    output_label_dir = output_dir / 'labels'\n",
    "    output_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    valid_class_ids = {0, 1, 2, 3}  # car, truck, bus, motorcycle\n",
    "    invalid_labels = []\n",
    "    valid_labels = 0\n",
    "    copied_images = 0\n",
    "    \n",
    "    # Supported image extensions\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    \n",
    "    # Check each label file\n",
    "    for label_file in label_dir.glob('*.txt'):\n",
    "        try:\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            if not lines:\n",
    "                invalid_labels.append((label_file, \"Empty file\"))\n",
    "                continue\n",
    "            \n",
    "            valid = True\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    invalid_labels.append((label_file, f\"Wrong number of columns ({len(parts)})\"))\n",
    "                    valid = False\n",
    "                    break\n",
    "                try:\n",
    "                    class_id = int(parts[0])\n",
    "                    if class_id not in valid_class_ids:\n",
    "                        invalid_labels.append((label_file, f\"Invalid class ID ({class_id})\"))\n",
    "                        valid = False\n",
    "                        break\n",
    "                    # Verify coordinates are valid floats\n",
    "                    for j in range(1, 5):\n",
    "                        float(parts[j])\n",
    "                except ValueError:\n",
    "                    invalid_labels.append((label_file, f\"Invalid number format in line: {line.strip()}\"))\n",
    "                    valid = False\n",
    "                    break\n",
    "            \n",
    "            if valid:\n",
    "                # Copy valid label to output directory\n",
    "                shutil.copy(label_file, output_label_dir / label_file.name)\n",
    "                valid_labels += 1\n",
    "                # Copy corresponding image (any supported extension)\n",
    "                img_found = False\n",
    "                for ext in image_extensions:\n",
    "                    img_file = image_dir / f'{label_file.stem}{ext}'\n",
    "                    if img_file.exists():\n",
    "                        shutil.copy(img_file, output_image_dir / img_file.name)\n",
    "                        copied_images += 1\n",
    "                        img_found = True\n",
    "                        break\n",
    "                if not img_found:\n",
    "                    logging.warning(f\"No image found for valid label {label_file.name}\")\n",
    "                    # Remove the copied label if no image is found\n",
    "                    os.remove(output_label_dir / label_file.name)\n",
    "                    valid_labels -= 1\n",
    "            else:\n",
    "                # Log invalid label, don't copy\n",
    "                img_found = False\n",
    "                for ext in image_extensions:\n",
    "                    img_file = image_dir / f'{label_file.stem}{ext}'\n",
    "                    if img_file.exists():\n",
    "                        img_found = True\n",
    "                        break\n",
    "                if not img_found:\n",
    "                    logging.warning(f\"No image found for invalid label {label_file.name}\")\n",
    "        except Exception as e:\n",
    "            invalid_labels.append((label_file, f\"Failed to process: {e}\"))\n",
    "            img_found = False\n",
    "            for ext in image_extensions:\n",
    "                img_file = image_dir / f'{label_file.stem}{ext}'\n",
    "                if img_file.exists():\n",
    "                    img_found = True\n",
    "                    break\n",
    "            if not img_found:\n",
    "                logging.warning(f\"No image found for invalid label {label_file.name}\")\n",
    "    \n",
    "    # Generate report\n",
    "    report = (\n",
    "        f\"Label Check Report:\\n\"\n",
    "        f\"- Total labels checked: {valid_labels + len(invalid_labels)}\\n\"\n",
    "        f\"- Valid labels copied: {valid_labels}\\n\"\n",
    "        f\"- Invalid labels skipped: {len(invalid_labels)}\\n\"\n",
    "        f\"- Images copied: {copied_images}\\n\"\n",
    "    )\n",
    "    if invalid_labels:\n",
    "        report += f\"- Invalid labels (first 5):\\n\"\n",
    "        for label_file, reason in invalid_labels[:5]:\n",
    "            report += f\"  - {label_file.name}: {reason}\\n\"\n",
    "    \n",
    "    logging.info(report)\n",
    "    print(f\"INFO: {report}\")\n",
    "    \n",
    "    # Save report to /kaggle/working/\n",
    "    report_path = Path('/kaggle/working/label_check_report.txt')\n",
    "    try:\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        print(f\"INFO: Report saved to {report_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save report: {e}\")\n",
    "        print(f\"ERROR: Failed to save report: {e}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    check_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.723100Z",
     "iopub.status.idle": "2025-05-03T00:27:24.723411Z",
     "shell.execute_reply": "2025-05-03T00:27:24.723260Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.723246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install osw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.725144Z",
     "iopub.status.idle": "2025-05-03T00:27:24.725446Z",
     "shell.execute_reply": "2025-05-03T00:27:24.725290Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.725278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from shutil import copyfile\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class DatasetAugmenter:\n",
    "    def __init__(self, image_dir, label_dir, output_image_dir, output_label_dir, image_exts=['.jpg', '.jpeg', '.png', '.bmp'], augmentations_per_image=1):\n",
    "        \"\"\"Initialize the augmenter with directories and settings.\"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.output_image_dir = output_image_dir\n",
    "        self.output_label_dir = output_label_dir\n",
    "        self.image_exts = image_exts\n",
    "        self.augmentations_per_image = augmentations_per_image\n",
    "        self.augmented_images = 0\n",
    "        self.augmented_labels = 0\n",
    "        self.valid_class_ids = {0, 1, 2, 3}  # car, truck, bus, motorcycle\n",
    "\n",
    "        # Create output directories\n",
    "        os.makedirs(self.output_image_dir, exist_ok=True)\n",
    "        os.makedirs(self.output_label_dir, exist_ok=True)\n",
    "\n",
    "        # Define augmentation pipeline matching aug_hyp.yaml\n",
    "        self.transform = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),  # Matches fliplr: 0.5\n",
    "            A.VerticalFlip(p=0.5),    # Matches flipud: 0.5\n",
    "            A.Rotate(limit=10, p=0.5),  # Matches degrees: 10.0\n",
    "            A.HueSaturationValue(hue_shift_limit=0.015*360, sat_shift_limit=0.7*100, val_shift_limit=0.4*100, p=0.5),  # Matches hsv_h, hsv_s, hsv_v\n",
    "            A.Affine(translate_percent=0.1, scale=(0.5, 1.5), shear=2.0, p=0.5),  # Matches translate, scale, shear\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "            A.GaussNoise(p=0.2),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3))\n",
    "\n",
    "    def augment_image(self, image, bboxes, class_labels):\n",
    "        \"\"\"Apply augmentation to a single image and its labels.\"\"\"\n",
    "        try:\n",
    "            augmented = self.transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "            return augmented['image'], augmented['bboxes'], augmented['class_labels']\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Augmentation failed: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def process_dataset(self):\n",
    "        \"\"\"Process all images and labels to create augmented dataset.\"\"\"\n",
    "        for image_file in os.listdir(self.image_dir):\n",
    "            # Check if file has a supported extension\n",
    "            if any(image_file.lower().endswith(ext) for ext in self.image_exts):\n",
    "                image_path = os.path.join(self.image_dir, image_file)\n",
    "                label_path = os.path.join(self.label_dir, image_file.rsplit('.', 1)[0] + '.txt')\n",
    "\n",
    "                if not os.path.exists(label_path):\n",
    "                    logging.warning(f\"No label found for {image_file}, skipping\")\n",
    "                    continue\n",
    "\n",
    "                # Read image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    logging.warning(f\"Failed to read image {image_file}, skipping\")\n",
    "                    continue\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Read labels\n",
    "                bboxes = []\n",
    "                class_labels = []\n",
    "                valid_label = True\n",
    "                try:\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.strip().split()\n",
    "                            if len(parts) != 5:\n",
    "                                valid_label = False\n",
    "                                break\n",
    "                            try:\n",
    "                                class_id = int(parts[0])\n",
    "                                if class_id not in self.valid_class_ids:\n",
    "                                    valid_label = False\n",
    "                                    break\n",
    "                                x_center, y_center, width, height = map(float, parts[1:])\n",
    "                                bboxes.append([x_center, y_center, width, height])\n",
    "                                class_labels.append(class_id)\n",
    "                            except ValueError:\n",
    "                                valid_label = False\n",
    "                                break\n",
    "                except Exception as e:\n",
    "                    valid_label = False\n",
    "                    logging.warning(f\"Failed to read label {label_path}: {e}\")\n",
    "\n",
    "                if not valid_label:\n",
    "                    logging.warning(f\"Skipping {image_file}: Invalid label format or class ID\")\n",
    "                    continue\n",
    "\n",
    "                # Copy original image and label\n",
    "                copyfile(image_path, os.path.join(self.output_image_dir, image_file))\n",
    "                copyfile(label_path, os.path.join(self.output_label_dir, image_file.rsplit('.', 1)[0] + '.txt'))\n",
    "\n",
    "                # Create augmented versions\n",
    "                for i in range(self.augmentations_per_image):\n",
    "                    aug_image, aug_bboxes, aug_class_labels = self.augment_image(image, bboxes, class_labels)\n",
    "                    if aug_image is not None:\n",
    "                        # Save augmented image\n",
    "                        aug_image_path = os.path.join(self.output_image_dir, f\"aug_{i}_{image_file}\")\n",
    "                        cv2.imwrite(aug_image_path, cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))\n",
    "                        self.augmented_images += 1\n",
    "\n",
    "                        # Save augmented labels\n",
    "                        aug_label_path = os.path.join(self.output_label_dir, f\"aug_{i}_{image_file.rsplit('.', 1)[0]}.txt\")\n",
    "                        with open(aug_label_path, 'w') as f:\n",
    "                            for class_id, bbox in zip(aug_class_labels, aug_bboxes):\n",
    "                                x_center, y_center, width, height = bbox\n",
    "                                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "                        self.augmented_labels += 1\n",
    "\n",
    "    def get_report(self):\n",
    "        \"\"\"Return a report of the augmentation results.\"\"\"\n",
    "        total_images = len([f for f in os.listdir(self.output_image_dir) if any(f.lower().endswith(ext) for ext in self.image_exts)])\n",
    "        total_labels = len([f for f in os.listdir(self.output_label_dir) if f.endswith('.txt')])\n",
    "        return (\n",
    "            f\"Augmentation Report:\\n\"\n",
    "            f\"- Created {self.augmented_images} augmented image files.\\n\"\n",
    "            f\"- Created {self.augmented_labels} augmented label files.\\n\"\n",
    "            f\"- Total files in augmented dataset: {total_images} images and {total_labels} labels.\"\n",
    "        )\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    augmenter = DatasetAugmenter(\n",
    "        image_dir='/kaggle/working/detection-cars-cleaned/images',\n",
    "        label_dir='/kaggle/working/detection-cars-cleaned/labels',\n",
    "        output_image_dir='/kaggle/working/detection-cars-cleaned/augmented_images',\n",
    "        output_label_dir='/kaggle/working/detection-cars-cleaned/augmented_labels',\n",
    "        image_exts=['.jpg', '.jpeg', '.png', '.bmp'],\n",
    "        augmentations_per_image=1\n",
    "    )\n",
    "    augmenter.process_dataset()\n",
    "    print(augmenter.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.726715Z",
     "iopub.status.idle": "2025-05-03T00:27:24.727046Z",
     "shell.execute_reply": "2025-05-03T00:27:24.726881Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.726867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def split_data(image_dir='/kaggle/working/detection-cars-cleaned/augmented_images',\n",
    "               label_dir='/kaggle/working/detection-cars-cleaned/augmented_labels',\n",
    "               output_dir='/kaggle/working/detection-cars-cleaned',\n",
    "               train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
    "               image_exts=['.jpg', '.jpeg', '.png', '.bmp']):\n",
    "    \"\"\"Split images and labels into train, val, test sets by moving files and create data.yaml.\"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    label_dir = Path(label_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Validate ratios\n",
    "    if abs(train_ratio + val_ratio + test_ratio - 1.0) > 0.01:\n",
    "        raise ValueError(\"Train, val, and test ratios must sum to 1.0\")\n",
    "    \n",
    "    # Check if input directories exist\n",
    "    if not image_dir.exists():\n",
    "        logging.error(f\"Image directory {image_dir} does not exist\")\n",
    "        print(f\"ERROR: Image directory {image_dir} does not exist\")\n",
    "        return\n",
    "    if not label_dir.exists():\n",
    "        logging.error(f\"Label directory {label_dir} does not exist\")\n",
    "        print(f\"ERROR: Label directory {label_dir} does not exist\")\n",
    "        return\n",
    "    \n",
    "    # Create output directories\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(output_dir / split / 'images', exist_ok=True)\n",
    "        os.makedirs(output_dir / split / 'labels', exist_ok=True)\n",
    "    \n",
    "    # Get list of images and ensure corresponding labels exist\n",
    "    image_files = [f for f in os.listdir(image_dir) if any(f.lower().endswith(ext) for ext in image_exts)]\n",
    "    valid_pairs = []\n",
    "    for img_file in image_files:\n",
    "        label_file = img_file.rsplit('.', 1)[0] + '.txt'\n",
    "        if os.path.exists(label_dir / label_file):\n",
    "            valid_pairs.append((img_file, label_file))\n",
    "        else:\n",
    "            logging.warning(f\"No label found for {img_file}, skipping\")\n",
    "    \n",
    "    # Shuffle and split\n",
    "    random.shuffle(valid_pairs)\n",
    "    total_pairs = len(valid_pairs)\n",
    "    train_end = int(train_ratio * total_pairs)\n",
    "    val_end = train_end + int(val_ratio * total_pairs)\n",
    "    \n",
    "    train_pairs = valid_pairs[:train_end]\n",
    "    val_pairs = valid_pairs[train_end:val_end]\n",
    "    test_pairs = valid_pairs[val_end:]\n",
    "    \n",
    "    # Move files to respective directories\n",
    "    def move_files(pairs, split):\n",
    "        img_count = 0\n",
    "        label_count = 0\n",
    "        for img_file, label_file in pairs:\n",
    "            try:\n",
    "                shutil.move(image_dir / img_file, output_dir / split / 'images' / img_file)\n",
    "                shutil.move(label_dir / label_file, output_dir / split / 'labels' / label_file)\n",
    "                img_count += 1\n",
    "                label_count += 1\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to move {img_file} or {label_file}: {e}\")\n",
    "        return img_count, label_count\n",
    "    \n",
    "    # Move files for each split\n",
    "    train_img_count, train_label_count = move_files(train_pairs, 'train')\n",
    "    val_img_count, val_label_count = move_files(val_pairs, 'val')\n",
    "    test_img_count, test_label_count = move_files(test_pairs, 'test')\n",
    "    \n",
    "    # Create data.yaml\n",
    "    data_yaml = {\n",
    "        'train': str(output_dir / 'train' / 'images'),\n",
    "        'val': str(output_dir / 'val' / 'images'),\n",
    "        'test': str(output_dir / 'test' / 'images'),\n",
    "        'nc': 4,\n",
    "        'names': ['car', 'truck', 'bus', 'motorcycle']\n",
    "    }\n",
    "    \n",
    "    yaml_path = output_dir / 'data.yaml'\n",
    "    try:\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
    "        logging.info(f\"data.yaml created at {yaml_path}\")\n",
    "        print(f\"INFO: data.yaml created at {yaml_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create data.yaml: {e}\")\n",
    "        print(f\"ERROR: Failed to create data.yaml: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Clean up old directories\n",
    "    try:\n",
    "        if image_dir.exists() and not any(image_dir.iterdir()):\n",
    "            shutil.rmtree(image_dir)\n",
    "            logging.info(f\"Removed empty directory {image_dir}\")\n",
    "        if label_dir.exists() and not any(label_dir.iterdir()):\n",
    "            shutil.rmtree(label_dir)\n",
    "            logging.info(f\"Removed empty directory {label_dir}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to clean up old directories: {e}\")\n",
    "    \n",
    "    # Generate report\n",
    "    report = (\n",
    "        f\"Data Split Report:\\n\"\n",
    "        f\"- Total valid image-label pairs: {total_pairs}\\n\"\n",
    "        f\"- Train: {train_img_count} images, {train_label_count} labels\\n\"\n",
    "        f\"- Val: {val_img_count} images, {val_label_count} labels\\n\"\n",
    "        f\"- Test: {test_img_count} images, {test_label_count} labels\\n\"\n",
    "        f\"- data.yaml saved at: {yaml_path}\"\n",
    "    )\n",
    "    logging.info(report)\n",
    "    print(f\"INFO: {report}\")\n",
    "    \n",
    "    with open(output_dir / 'data_split_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    print(f\"INFO: Report saved to {output_dir / 'data_split_report.txt'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.727951Z",
     "iopub.status.idle": "2025-05-03T00:27:24.728161Z",
     "shell.execute_reply": "2025-05-03T00:27:24.728067Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.728058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_aug_hyp_yaml(output_path='/kaggle/working/aug_hyp.yaml'):\n",
    "    \"\"\"Create aug_hyp.yaml with training and augmentation hyperparameters.\"\"\"\n",
    "    aug_hyp = {\n",
    "        'optimizer': 'AdamW',\n",
    "        'lr0': 0.001,\n",
    "        'lrf': 0.01,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.005,\n",
    "        'warmup_epochs': 3.0,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        'box': 7.5,\n",
    "        'cls': 1.0,\n",
    "        'dfl': 1.5,\n",
    "        'kobj': 1.0,\n",
    "        'iou': 0.5,\n",
    "        'conf': 0.25,\n",
    "        'hsv_h': 0.015,\n",
    "        'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4,\n",
    "        'degrees': 10.0,\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'shear': 2.0,\n",
    "        'perspective': 0.0,\n",
    "        'flipud': 0.5,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.5,\n",
    "        'mixup': 0.2,\n",
    "        'copy_paste': 0.0,\n",
    "        'auto_augment': 'none',\n",
    "        'erasing': 0.0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(output_path, 'w') as f:\n",
    "            yaml.safe_dump(aug_hyp, f, sort_keys=False)\n",
    "        logging.info(f\"aug_hyp.yaml created at {output_path}\")\n",
    "        print(f\"INFO: aug_hyp.yaml created at {output_path}\")\n",
    "        \n",
    "        # Verify file exists\n",
    "        if Path(output_path).exists():\n",
    "            with open(output_path, 'r') as f:\n",
    "                print(f\"INFO: Contents of aug_hyp.yaml:\\n{f.read()}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"aug_hyp.yaml was not created at {output_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create aug_hyp.yaml: {e}\")\n",
    "        print(f\"ERROR: Failed to create aug_hyp.yaml: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_aug_hyp_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Training Note =====================\n",
    "# Phase 1: Trained from scratch using yolov8l.pt for 33 epochs\n",
    "# Phase 2: Resumed training from saved checkpoint (best.pt) for 17 additional epochs\n",
    "# Total training: 50 epochs\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T00:27:24.729234Z",
     "iopub.status.idle": "2025-05-03T00:27:24.729493Z",
     "shell.execute_reply": "2025-05-03T00:27:24.729364Z",
     "shell.execute_reply.started": "2025-05-03T00:27:24.729353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class YOLOv8Trainer:\n",
    "    \"\"\"Class to handle YOLOv8l training with fine-tuning, early stopping, and checkpoint cleanup.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data_yaml='/kaggle/working/detection-cars-cleaned/data.yaml',\n",
    "                 hyp_yaml='/kaggle/working/aug_hyp.yaml',\n",
    "                 output_dir='/kaggle/working/runs',\n",
    "                 epochs=50,\n",
    "                 batch_size=16,\n",
    "                 imgsz=640,\n",
    "                 patience=20):\n",
    "        \"\"\"Initialize trainer with training configurations.\"\"\"\n",
    "        self.data_yaml = Path(data_yaml)\n",
    "        self.hyp_yaml = Path(hyp_yaml)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.imgsz = imgsz\n",
    "        self.patience = patience\n",
    "        self.model = None\n",
    "        self.hyp = None\n",
    "        self.weights_dir = None\n",
    "        \n",
    "    def clean_old_checkpoints(self):\n",
    "        \"\"\"Remove old checkpoints, keep only best.pt and last.pt.\"\"\"\n",
    "        for checkpoint in self.weights_dir.glob(\"epoch_*.pt\"):\n",
    "            try:\n",
    "                checkpoint.unlink()\n",
    "                logging.info(f\"Removed checkpoint: {checkpoint}\")\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to remove {checkpoint}: {e}\")\n",
    "    \n",
    "    def load_hyp_yaml(self):\n",
    "        \"\"\"Load hyperparameters from YAML file.\"\"\"\n",
    "        try:\n",
    "            with open(self.hyp_yaml, 'r') as f:\n",
    "                self.hyp = yaml.safe_load(f)\n",
    "            logging.info(f\"Loaded hyperparameters from {self.hyp_yaml}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load {self.hyp_yaml}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def validate_files(self):\n",
    "        \"\"\"Check if data.yaml and hyp.yaml exist.\"\"\"\n",
    "        if not self.data_yaml.exists():\n",
    "            logging.error(f\"Data YAML file {self.data_yaml} does not exist\")\n",
    "            return False\n",
    "        if not self.hyp_yaml.exists():\n",
    "            logging.error(f\"Hyp YAML file {self.hyp_yaml} does not exist\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"Setup training: validate files, load hyperparameters, create output dir.\"\"\"\n",
    "        if not self.validate_files():\n",
    "            return False\n",
    "        self.load_hyp_yaml()\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        logging.info(\"Training setup completed\")\n",
    "        return True\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train YOLOv8l model with fine-tuning, validate every 10 epochs.\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO('yolov8l.pt')  # Load pre-trained YOLOv8l\n",
    "            epoch_step = 10  # Validate every 10 epochs\n",
    "            current_epoch = 0\n",
    "            \n",
    "            while current_epoch < self.epochs:\n",
    "                # Calculate remaining epochs for this step\n",
    "                epochs_to_run = min(epoch_step, self.epochs - current_epoch)\n",
    "                \n",
    "                # Train for epochs_to_run\n",
    "                results = self.model.train(\n",
    "                    data=str(self.data_yaml),\n",
    "                    epochs=epochs_to_run,\n",
    "                    batch=self.batch_size,\n",
    "                    imgsz=self.imgsz,\n",
    "                    device=0,\n",
    "                    project=str(self.output_dir),\n",
    "                    name='yolov8l_vehicles',\n",
    "                    exist_ok=True,\n",
    "                    save=True,\n",
    "                    save_period=-1,\n",
    "                    plots=True,\n",
    "                    verbose=True,\n",
    "                    patience=self.patience,\n",
    "                    resume=current_epoch > 0,  # Resume from previous checkpoint if not first step\n",
    "                    **self.hyp\n",
    "                )\n",
    "                \n",
    "                # Update current epoch\n",
    "                current_epoch += epochs_to_run\n",
    "                \n",
    "                # Run validation manually after every epoch_step\n",
    "                if current_epoch % epoch_step == 0:  # Don't validate after final epoch\n",
    "                    val_metrics = self.model.val(data=str(self.data_yaml), split='val')\n",
    "                    logging.info(f\"Validation Metrics at epoch {current_epoch}: {val_metrics}\")\n",
    "                    print(f\"INFO: Validation Metrics at epoch {current_epoch}: {val_metrics}\")\n",
    "                \n",
    "                # Clean old checkpoints\n",
    "                self.weights_dir = self.output_dir / 'yolov8l_vehicles' / 'weights'\n",
    "                self.clean_old_checkpoints()\n",
    "            \n",
    "            logging.info(\"Training completed\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Training failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate model on test set.\"\"\"\n",
    "        if self.model is None:\n",
    "            logging.error(\"No model for evaluation\")\n",
    "            return\n",
    "        try:\n",
    "            metrics = self.model.val(data=str(self.data_yaml), split='test')\n",
    "            logging.info(f\"Test Metrics: {metrics}\")\n",
    "            print(f\"INFO: Test Metrics: {metrics}\")\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Evaluation failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def save_final_model(self):\n",
    "        \"\"\"Save final model as final.pt.\"\"\"\n",
    "        if self.model is None:\n",
    "            logging.error(\"No model to save\")\n",
    "            return\n",
    "        try:\n",
    "            final_path = self.weights_dir / 'final.pt'\n",
    "            self.model.save(str(final_path))\n",
    "            logging.info(f\"Final model saved to {final_path}\")\n",
    "            print(f\"INFO: Final model saved to {final_path}\")\n",
    "            self.clean_old_checkpoints()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save final model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run full training pipeline.\"\"\"\n",
    "        if not self.setup():\n",
    "            return\n",
    "        self.train()\n",
    "        self.evaluate()\n",
    "        self.save_final_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer = YOLOv8Trainer()\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    force=True,\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('/kaggle/working/logs.txt')\n",
    "    ]\n",
    ")\n",
    "\n",
    "class YOLOv8Trainer:\n",
    "    def __init__(self,\n",
    "                 data_yaml='/kaggle/working/detection-cars-cleaned/data.yaml',\n",
    "                 hyp_yaml='/kaggle/working/aug_hyp.yaml',\n",
    "                 output_dir='/kaggle/working/runs',\n",
    "                 epochs=30,\n",
    "                 batch_size=16,\n",
    "                 imgsz=640,\n",
    "                 patience=20,\n",
    "                 save_period=1):\n",
    "        print(\"Initializing YOLOv8Trainer\")\n",
    "        logging.info(\"Initializing YOLOv8Trainer\")\n",
    "        \n",
    "        self.data_yaml = Path(data_yaml)\n",
    "        self.hyp_yaml = Path(hyp_yaml)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.imgsz = imgsz\n",
    "        self.patience = patience\n",
    "        self.save_period = save_period\n",
    "        self.model = None\n",
    "        self.hyp = None\n",
    "        self.weights_dir = None\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        logging.info(f\"Using device: {self.device}\")\n",
    "        self.checkpoint_input_path = Path('/kaggle/input/mostafachekpoints/pytorch/default/1/mostafacheckpoints.pt') \n",
    "        self.checkpoint_output_path = None\n",
    "        self.best_score = 0.0\n",
    "        self.best_checkpoint_score = 0.0\n",
    "        self.best_recall = 0.0\n",
    "        self.no_improve_epochs = 0\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def validate_files(self):\n",
    "        \"\"\"Check if data.yaml and hyp.yaml exist.\"\"\"\n",
    "        print(\"Entering validate_files\")\n",
    "        logging.info(\"Entering validate_files\")\n",
    "        \n",
    "        valid = True\n",
    "        if not self.data_yaml.exists():\n",
    "            logging.error(f\"Data YAML file {self.data_yaml} does not exist\")\n",
    "            print(f\"ERROR: Data YAML file {self.data_yaml} does not exist\")\n",
    "            valid = False\n",
    "        if not self.hyp_yaml.exists():\n",
    "            logging.error(f\"Hyp YAML file {self.hyp_yaml} does not exist\")\n",
    "            print(f\"ERROR: Hyp YAML file {self.hyp_yaml} does not exist\")\n",
    "            valid = False\n",
    "        return valid\n",
    "\n",
    "    def load_hyp_yaml(self):\n",
    "        \"\"\"Load hyperparameters from YAML file.\"\"\"\n",
    "        print(\"Entering load_hyp_yaml\")\n",
    "        logging.info(\"Entering load_hyp_yaml\")\n",
    "        \n",
    "        if not self.hyp_yaml.exists():\n",
    "            logging.error(f\"Hyperparameter file {self.hyp_yaml} not found.\")\n",
    "            print(f\"ERROR: Hyperparameter file {self.hyp_yaml} not found.\")\n",
    "            raise FileNotFoundError(f\"Hyperparameter file {self.hyp_yaml} not found.\")\n",
    "        try:\n",
    "            with open(self.hyp_yaml, 'r') as f:\n",
    "                self.hyp = yaml.safe_load(f)\n",
    "            self.hyp['cls'] = self.hyp.get('cls', 0.5) * 1.5\n",
    "            logging.info(f\"Loaded hyperparameters from {self.hyp_yaml}\")\n",
    "            print(f\"Loaded hyperparameters from {self.hyp_yaml}\")\n",
    "            if not isinstance(self.hyp, dict):\n",
    "                logging.error(f\"Hyperparameters loaded from {self.hyp_yaml} are not a dictionary.\")\n",
    "                print(f\"ERROR: Hyperparameters loaded from {self.hyp_yaml} are not a dictionary.\")\n",
    "                raise ValueError(\"Invalid hyperparameter format\")\n",
    "        except yaml.YAMLError as e:\n",
    "            logging.error(f\"Error parsing YAML file {self.hyp_yaml}: {e}\")\n",
    "            print(f\"ERROR: Error parsing YAML file {self.hyp_yaml}: {e}\")\n",
    "            raise ValueError(f\"Error parsing YAML file {self.hyp_yaml}\") from e\n",
    "\n",
    "    def load_initial_model(self):\n",
    "        \"\"\"Load pretrained yolov8l.pt, update head for nc=4, then load checkpoint state dict without freeze.\"\"\"\n",
    "        print(\"Entering load_initial_model\")\n",
    "        logging.info(\"Entering load_initial_model\")\n",
    "        \n",
    "        try:\n",
    "            # Validate data.yaml\n",
    "            with open(self.data_yaml, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            if data_config['nc'] != 4:\n",
    "                raise ValueError(f\"Expected 4 classes in {self.data_yaml}, found {data_config['nc']}\")\n",
    "            expected_names = ['car', 'truck', 'bus', 'motorcycle']\n",
    "            if data_config['names'] != expected_names:\n",
    "                raise ValueError(f\"Expected class names {expected_names} in {self.data_yaml}, found {data_config['names']}\")\n",
    "            \n",
    "            # Load pretrained yolov8l.pt\n",
    "            self.model = YOLO('yolov8l.pt')\n",
    "            self.model.model.yaml['nc'] = 4\n",
    "            \n",
    "            # No freeze: all layers are trainable\n",
    "            for param in self.model.model.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            # Update head for nc=4\n",
    "            head_module = self.model.model.model[22]\n",
    "            for i in range(3):\n",
    "                conv_layer = head_module.cv3[i][2]\n",
    "                if conv_layer.out_channels == 80:\n",
    "                    new_conv = nn.Conv2d(\n",
    "                        in_channels=conv_layer.in_channels,\n",
    "                        out_channels=4,\n",
    "                        kernel_size=conv_layer.kernel_size,\n",
    "                        stride=conv_layer.stride,\n",
    "                        padding=conv_layer.padding,\n",
    "                        bias=conv_layer.bias is not None\n",
    "                    ).to(self.device)\n",
    "                    head_module.cv3[i][2] = new_conv\n",
    "            \n",
    "            # Load checkpoint state dict\n",
    "            checkpoint_path = str(self.checkpoint_input_path)\n",
    "            if not Path(checkpoint_path).exists():\n",
    "                logging.error(f\"Checkpoint file {checkpoint_path} not found.\")\n",
    "                print(f\"ERROR: Checkpoint file {checkpoint_path} not found.\")\n",
    "                raise FileNotFoundError(f\"Checkpoint file {checkpoint_path} not found.\")\n",
    "            \n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            # Verify parameter count after loading\n",
    "            total_params = sum(p.numel() for p in self.model.model.parameters() if p.requires_grad)\n",
    "            logging.info(f\"Total trainable parameters after loading: {total_params}\")\n",
    "            print(f\"Total trainable parameters after loading: {total_params}\")\n",
    "            \n",
    "            # Log detailed parameter groups for debugging\n",
    "            bn_weights = [name for name, param in self.model.model.named_parameters() if 'bn' in name and '.weight' in name]\n",
    "            bn_biases = [name for name, param in self.model.model.named_parameters() if 'bn' in name and '.bias' in name]\n",
    "            other_weights = [name for name, param in self.model.model.named_parameters() if '.weight' in name and 'bn' not in name]\n",
    "            other_biases = [name for name, param in self.model.model.named_parameters() if '.bias' in name and 'bn' not in name]\n",
    "            logging.info(f\"BatchNorm weights count: {len(bn_weights)}\")\n",
    "            logging.info(f\"BatchNorm biases count: {len(bn_biases)}\")\n",
    "            logging.info(f\"Other weights count: {len(other_weights)}\")\n",
    "            logging.info(f\"Other biases count: {len(other_biases)}\")\n",
    "            print(f\"BatchNorm weights count: {len(bn_weights)}\")\n",
    "            print(f\"BatchNorm biases count: {len(bn_biases)}\")\n",
    "            print(f\"Other weights count: {len(other_weights)}\")\n",
    "            print(f\"Other biases count: {len(other_biases)}\")\n",
    "            \n",
    "            logging.info(f\"Loaded pretrained yolov8l.pt with nc=4 and checkpoint {checkpoint_path} (no freeze)\")\n",
    "            print(f\"Loaded pretrained yolov8l.pt with nc=4 and checkpoint {checkpoint_path} (no freeze)\")\n",
    "        except Exception as error:\n",
    "            logging.critical(f\"Failed to load model or checkpoint: {str(error)}\")\n",
    "            print(f\"CRITICAL: Failed to load model or checkpoint: {str(error)}\")\n",
    "            raise RuntimeError(\"Could not load model or checkpoint.\") from error\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Setup training: validate files, load hyperparameters, create output dir.\"\"\"\n",
    "        print(\"Entering setup\")\n",
    "        logging.info(\"Entering setup\")\n",
    "        \n",
    "        if not self.validate_files():\n",
    "            logging.error(\"Setup failed: Required files missing.\")\n",
    "            print(\"ERROR: Setup failed: Required files missing.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            self.load_hyp_yaml()\n",
    "            os.makedirs(self.output_dir, exist_ok=True)\n",
    "            self.load_initial_model()\n",
    "            if self.model is None:\n",
    "                logging.error(\"Setup failed: Model not initialized.\")\n",
    "                print(\"ERROR: Setup failed: Model not initialized.\")\n",
    "                return False\n",
    "            self.weights_dir = self.output_dir / 'yolov8l_vehicles_custom_weights'\n",
    "            os.makedirs(self.weights_dir, exist_ok=True)\n",
    "            logging.info(\"Training setup completed\")\n",
    "            print(\"Training setup completed\")\n",
    "            return True\n",
    "        except Exception as error:\n",
    "            logging.critical(f\"Setup failed: {str(error)}\")\n",
    "            print(f\"CRITICAL: Setup failed: {str(error)}\")\n",
    "            return False\n",
    "\n",
    "    def clean_old_checkpoints(self):\n",
    "        \"\"\"Remove old checkpoints except required files.\"\"\"\n",
    "        print(\"Entering clean_old_checkpoints\")\n",
    "        logging.info(\"Entering clean_old_checkpoints\")\n",
    "        \n",
    "        if not self.weights_dir:\n",
    "            logging.warning(\"Weights directory not set. Skipping checkpoint cleaning.\")\n",
    "            print(\"WARNING: Weights directory not set. Skipping checkpoint cleaning.\")\n",
    "            return \n",
    "        keep_files = ['finalchechpoints.pt', 'bestmodel.pt', 'lastfinal.pt', 'mostafafinal.pt']\n",
    "        checkpoint_dir = self.weights_dir / 'check_points1'\n",
    "        try:\n",
    "            if checkpoint_dir.exists():\n",
    "                for checkpoint in checkpoint_dir.glob(\"*.pt\"):\n",
    "                    if checkpoint.name not in keep_files:\n",
    "                        checkpoint.unlink()\n",
    "                        logging.info(f\"Removed old checkpoint: {checkpoint}\")\n",
    "                        print(f\"Removed old checkpoint: {checkpoint}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error cleaning checkpoints in {checkpoint_dir}: {e}\")\n",
    "            print(f\"ERROR: Error cleaning checkpoints in {checkpoint_dir}: {e}\")\n",
    "\n",
    "    def save_checkpoint(self, epoch, map50_95, recall):\n",
    "        \"\"\"Save checkpoint with model weights, optimizer state, epoch, loss, and metrics.\"\"\"\n",
    "        print(f\"Entering save_checkpoint for epoch {epoch + 1}/{self.epochs}\")\n",
    "        logging.info(f\"Entering save_checkpoint for epoch {epoch + 1}/{self.epochs}\")\n",
    "        \n",
    "        if not self.weights_dir:\n",
    "            logging.error(\"Cannot save checkpoint: Weights directory not set.\")\n",
    "            print(\"ERROR: Cannot save checkpoint: Weights directory not set.\")\n",
    "            return\n",
    "            \n",
    "        checkpoint_dir = self.weights_dir / 'check_points1'\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        print(f\"Created/Verified checkpoint directory: {checkpoint_dir}\")\n",
    "        logging.info(f\"Created/Verified checkpoint directory: {checkpoint_dir}\")\n",
    "        \n",
    "        checkpoint_path = checkpoint_dir / \"finalchechpoints.pt\"\n",
    "        last_path = checkpoint_dir / \"lastfinal.pt\"\n",
    "        best_path = checkpoint_dir / \"bestmodel.pt\"\n",
    "        self.checkpoint_output_path = checkpoint_path\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "        \n",
    "        if self.model is None or self.model.model is None:\n",
    "            logging.error(\"Model not initialized. Cannot save state dict.\")\n",
    "            print(\"ERROR: Model not initialized. Cannot save state dict.\")\n",
    "            return\n",
    "            \n",
    "        optimizer_state_dict = None\n",
    "        if self.model.trainer and self.model.trainer.optimizer:\n",
    "            optimizer_state_dict = self.model.trainer.optimizer.state_dict()\n",
    "        else:\n",
    "            logging.warning(\"Optimizer not available. Saving checkpoint without optimizer state.\")\n",
    "            print(\"WARNING: Optimizer not available. Saving checkpoint without optimizer state.\")\n",
    "\n",
    "        train_loss = getattr(self.model.trainer, 'loss', 0.0) if self.model.trainer else 0.0\n",
    "        val_loss = getattr(self.model.trainer, 'val_loss', 0.0) if self.model.trainer else 0.0\n",
    "        loss_diff = abs(train_loss - val_loss)\n",
    "        stability_penalty = min(max(0, (loss_diff - 0.1) * 0.05), 1.0)  # Cap penalty at 1.0\n",
    "\n",
    "        score = 0.5 * map50_95 + 0.5 * recall - stability_penalty\n",
    "\n",
    "        try:\n",
    "            checkpoint_data = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_state_dict,\n",
    "                'loss': train_loss,\n",
    "                'map50_95': map50_95,\n",
    "                'recall': recall,\n",
    "                'score': score,\n",
    "                'timestamp': timestamp,\n",
    "                'best_score_so_far': self.best_score,\n",
    "                'best_recall': self.best_recall,\n",
    "                'no_improve_epochs': self.no_improve_epochs\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint_data, checkpoint_path)\n",
    "            logging.info(f\"Saved checkpoint: {checkpoint_path} (Epoch: {epoch + 1}/{self.epochs}, Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f})\")\n",
    "            print(f\"Saved checkpoint: {checkpoint_path} (Epoch: {epoch + 1}/{self.epochs}, Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f})\")\n",
    "            \n",
    "            torch.save(self.model.model.state_dict(), last_path)\n",
    "            logging.info(f\"Saved last model state dict: {last_path} (Epoch: {epoch + 1}/{self.epochs})\")\n",
    "            print(f\"Saved last model state dict: {last_path} (Epoch: {epoch + 1}/{self.epochs})\")\n",
    "            \n",
    "            if score > self.best_score:\n",
    "                self.best_score = score\n",
    "                torch.save(self.model.model.state_dict(), best_path)\n",
    "                logging.info(f\"Updated best model state dict: {best_path} (Epoch: {epoch + 1}/{self.epochs}, Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f})\")\n",
    "                print(f\"Updated best model state dict: {best_path} (Epoch: {epoch + 1}/{self.epochs}, Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f})\")\n",
    "            \n",
    "            if recall > self.best_recall:\n",
    "                self.best_recall = recall\n",
    "                logging.info(f\"New best recall: {recall:.4f} at epoch {epoch + 1}/{self.epochs}\")\n",
    "                print(f\"New best recall: {recall:.4f} at epoch {epoch + 1}/{self.epochs}\")\n",
    "            \n",
    "            try:\n",
    "                dataset_dir = Path('/kaggle/working/checkpoint_dataset')\n",
    "                os.makedirs(dataset_dir, exist_ok=True)\n",
    "                shutil.copy(str(checkpoint_path), str(dataset_dir / \"finalchechpoints.pt\"))\n",
    "                logging.info(f\"Copied checkpoint to dataset directory: {dataset_dir}\")\n",
    "                print(f\"Copied checkpoint to dataset directory: {dataset_dir}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to copy checkpoint to dataset directory: {e}\")\n",
    "                print(f\"ERROR: Failed to copy checkpoint to dataset directory: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save checkpoint data to {checkpoint_path}: {e}\")\n",
    "            print(f\"ERROR: Failed to save checkpoint data to {checkpoint_path}: {e}\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer):\n",
    "        \"\"\"Callback to run at the end of each training epoch.\"\"\"\n",
    "        print(f\"Entering on_train_epoch_end for epoch {trainer.epoch + 1}/{self.epochs}\")\n",
    "        logging.info(f\"Entering on_train_epoch_end for epoch {trainer.epoch + 1}/{self.epochs}\")\n",
    "        \n",
    "        self.current_epoch = trainer.epoch\n",
    "        \n",
    "        if not hasattr(trainer, 'metrics'):\n",
    "            logging.error(\"trainer.metrics not available. Cannot compute mAP and recall.\")\n",
    "            print(\"ERROR: trainer.metrics not available. Cannot compute mAP and recall.\")\n",
    "            map50_95 = 0.0\n",
    "            recall = 0.0\n",
    "        else:\n",
    "            print(f\"trainer.metrics contents: {trainer.metrics}\")\n",
    "            logging.info(f\"trainer.metrics contents: {trainer.metrics}\")\n",
    "            map50_95 = trainer.metrics.get('metrics/mAP50-95(B)', 0.0)\n",
    "            recall = trainer.metrics.get('metrics/recall(B)', 0.0)\n",
    "            if map50_95 == 0.0 or recall == 0.0:\n",
    "                logging.warning(\"mAP or recall is 0.0. Possible issue with validation data or metrics computation.\")\n",
    "                print(\"WARNING: mAP or recall is 0.0. Possible issue with validation data or metrics computation.\")\n",
    "\n",
    "        train_loss = getattr(trainer, 'loss', 0.0) if hasattr(trainer, 'loss') else 0.0\n",
    "        val_loss = getattr(self.model.trainer, 'val_loss', 0.0) if self.model.trainer else 0.0\n",
    "        loss_diff = abs(train_loss - val_loss)\n",
    "        stability_penalty = min(max(0, (loss_diff - 0.1) * 0.05), 1.0)  # Cap penalty at 1.0\n",
    "\n",
    "        score = 0.5 * map50_95 + 0.5 * recall - stability_penalty\n",
    "\n",
    "        logging.info(f\"Epoch {self.current_epoch + 1}/{self.epochs} completed. Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f}, Loss Diff: {loss_diff:.4f}\")\n",
    "        print(f\"Epoch {self.current_epoch + 1}/{self.epochs} completed. Score: {score:.4f}, mAP@50:95: {map50_95:.4f}, Recall: {recall:.4f}, Loss Diff: {loss_diff:.4f}\")\n",
    "\n",
    "        self.save_checkpoint(self.current_epoch, map50_95, recall)\n",
    "\n",
    "        if score > self.best_score:\n",
    "            logging.info(f\"Score improved from {self.best_score:.4f} to {score:.4f} at epoch {self.current_epoch + 1}/{self.epochs}.\")\n",
    "            print(f\"Score improved from {self.best_score:.4f} to {score:.4f} at epoch {self.current_epoch + 1}/{self.epochs}.\")\n",
    "            self.best_score = score\n",
    "            self.no_improve_epochs = 0\n",
    "        else:\n",
    "            self.no_improve_epochs += 1\n",
    "            logging.info(f\"Score did not improve ({score:.4f} vs best {self.best_score:.4f}). No improvement for {self.no_improve_epochs} epoch(s).\")\n",
    "            print(f\"Score did not improve ({score:.4f} vs best {self.best_score:.4f}). No improvement for {self.no_improve_epochs} epoch(s).\")\n",
    "\n",
    "    def save_crash_checkpoint(self):\n",
    "        \"\"\"Save a checkpoint in case of a crash.\"\"\"\n",
    "        print(\"Entering save_crash_checkpoint\")\n",
    "        logging.info(\"Entering save_crash_checkpoint\")\n",
    "        try:\n",
    "            checkpoint_dir = self.output_dir / 'yolov8l_vehicles_custom_weights' / 'check_points1'\n",
    "            checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "            crash_checkpoint_path = checkpoint_dir / 'crash_checkpoint.pt'\n",
    "            torch.save({\n",
    "                'epoch': self.current_epoch,\n",
    "                'model_state_dict': self.model.model.state_dict(),\n",
    "                'optimizer_state_dict': self.model.trainer.optimizer.state_dict() if hasattr(self.model, 'trainer') and self.model.trainer and hasattr(self.model.trainer, 'optimizer') else None,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "            }, crash_checkpoint_path)\n",
    "            print(f\"Saved crash checkpoint: {crash_checkpoint_path}\")\n",
    "            logging.info(f\"Saved crash checkpoint: {crash_checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save crash checkpoint: {str(e)}\")\n",
    "            print(f\"ERROR: Failed to save crash checkpoint: {str(e)}\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train YOLOv8l model starting from checkpoint for 17 epochs with targeted augmentation for weak classes.\"\"\"\n",
    "        print(\"Entering train\")\n",
    "        logging.info(\"Entering train\")\n",
    "        \n",
    "        if self.model is None or self.hyp is None or self.weights_dir is None:\n",
    "            logging.error(\"Training cannot start: Setup was not completed successfully.\")\n",
    "            print(\"ERROR: Training cannot start: Setup was not completed successfully.\")\n",
    "            return None\n",
    "    \n",
    "        try:\n",
    "            checkpoint_path = str(self.checkpoint_input_path)\n",
    "            if not Path(checkpoint_path).exists():\n",
    "                logging.error(f\"Checkpoint file not found at {checkpoint_path}. Cannot resume training.\")\n",
    "                print(f\"ERROR: Checkpoint file not found at {checkpoint_path}. Cannot resume training.\")\n",
    "                raise RuntimeError(f\"Checkpoint file not found at {checkpoint_path}\")\n",
    "    \n",
    "            logging.info(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "            print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "            # Load checkpoint to get model state and optimizer state\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "            logging.info(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "            print(f\"Checkpoint epoch: {checkpoint.get('epoch', -1)}\")\n",
    "            logging.info(f\"Checkpoint epoch: {checkpoint.get('epoch', -1)}\")\n",
    "    \n",
    "            # Load model state\n",
    "            self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "            # Analyze checkpoint optimizer_state_dict\n",
    "            print(\"Analyzing optimizer_state_dict from checkpoint...\")\n",
    "            logging.info(\"Analyzing optimizer_state_dict from checkpoint...\")\n",
    "            checkpoint_optimizer_state = checkpoint['optimizer_state_dict']\n",
    "            for i, group in enumerate(checkpoint_optimizer_state['param_groups']):\n",
    "                num_params = len(group['params'])\n",
    "                print(f\"Checkpoint parameter group {i}: {num_params} parameters, lr: {group['lr']}, weight_decay: {group['weight_decay']}\")\n",
    "                logging.info(f\"Checkpoint parameter group {i}: {num_params} parameters, lr: {group['lr']}, weight_decay: {group['weight_decay']}\")\n",
    "    \n",
    "            self.best_score = checkpoint.get('best_score_so_far', 0.0)\n",
    "            self.best_recall = checkpoint.get('best_recall', 0.0)\n",
    "            self.no_improve_epochs = 0  # Reset, but early stopping is disabled\n",
    "    \n",
    "            # Set epochs to 17 to start from epoch 1\n",
    "            remaining_epochs = 17  # Train for 17 epochs starting from 1\n",
    "            start_epoch = 1\n",
    "    \n",
    "            print(f\"Starting training from epoch {start_epoch} for {remaining_epochs} epochs\")\n",
    "            logging.info(f\"Starting training from epoch {start_epoch} for {remaining_epochs} epochs\")\n",
    "    \n",
    "            # Override hyperparameters\n",
    "            self.hyp['cls'] = 1.0\n",
    "            self.hyp['dfl'] = 1.0\n",
    "            self.hyp['patience'] = 1000\n",
    "            self.hyp['mixup'] = 0.5\n",
    "            self.hyp['mosaic'] = 0.8\n",
    "            self.hyp['copy_paste'] = 0.95\n",
    "            self.hyp['copy_paste_mode'] = 'flip'\n",
    "            self.hyp['conf'] = 0.1\n",
    "    \n",
    "            print(f\"Set cls weight to {self.hyp['cls']}, dfl weight to {self.hyp['dfl']}, mixup to {self.hyp['mixup']}, mosaic to {self.hyp['mosaic']}, copy_paste to {self.hyp['copy_paste']}, conf to {self.hyp['conf']}\")\n",
    "            logging.info(f\"Set cls weight to {self.hyp['cls']}, dfl weight to {self.hyp['dfl']}, mixup to {self.hyp['mixup']}, mosaic to {self.hyp['mosaic']}, copy_paste to {self.hyp['copy_paste']}, conf to {self.hyp['conf']}\")\n",
    "    \n",
    "            # Modified targeted copy-paste augmentation with albumentations\n",
    "            def targeted_copy_paste(dataset, labels, prob=0.95):\n",
    "                if np.random.rand() > prob or not isinstance(labels, dict):\n",
    "                    return labels\n",
    "                weak_classes = [2, 3]  # bus (2), motorcycle (3)\n",
    "                new_labels = labels.copy()\n",
    "                weak_images = [i for i, lbls in enumerate(dataset.labels) if any(lbl[0] in weak_classes for lbl in lbls)]\n",
    "                if weak_images:\n",
    "                    random_idx = np.random.choice(weak_images)\n",
    "                    weak_labels = [lbl for lbl in dataset.labels[random_idx] if lbl[0] in weak_classes]\n",
    "                    if weak_labels:\n",
    "                        weak_labels = weak_labels[:3]\n",
    "                        new_bboxes = np.array([lbl[1:] for lbl in weak_labels], dtype=np.float32)\n",
    "                        new_cls = np.array([lbl[0] for lbl in weak_labels], dtype=np.float32)\n",
    "                        \n",
    "                        transform = A.Compose([\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.Rotate(limit=15, p=0.6),\n",
    "                            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.4),\n",
    "                            A.GaussNoise(p=0.2),\n",
    "                            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "                        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3))\n",
    "                        \n",
    "                        img_path = dataset.data[random_idx]['im_file']\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is None:\n",
    "                            logging.warning(f\"Failed to load image {img_path} for targeted copy-paste\")\n",
    "                            return labels\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        augmented = transform(image=img, bboxes=new_bboxes, class_labels=new_cls)\n",
    "                        new_bboxes = augmented['bboxes']\n",
    "                        new_cls = augmented['class_labels']\n",
    "                        \n",
    "                        if 'cls' in new_labels and 'bboxes' in new_labels:\n",
    "                            new_labels['cls'] = np.concatenate([new_labels['cls'], new_cls])\n",
    "                            new_labels['bboxes'] = np.concatenate([new_labels['bboxes'], new_bboxes])\n",
    "                        else:\n",
    "                            new_labels = {\n",
    "                                'cls': new_cls,\n",
    "                                'bboxes': new_bboxes,\n",
    "                                'img_id': new_labels.get('img_id', 0),\n",
    "                                'img_shape': new_labels.get('img_shape', (640, 640)),\n",
    "                                'im_file': new_labels.get('im_file', '')\n",
    "                            }\n",
    "                return new_labels\n",
    "    \n",
    "            # Modified class-aware sampler with higher weight for weak classes\n",
    "            def get_class_aware_sampler(dataset):\n",
    "                weights = [5.0 if any(label[0] in [2, 3] for label in labels) else 1.0 for labels in dataset.labels]\n",
    "                return WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "    \n",
    "            # Custom collate function to return a dictionary compatible with Ultralytics\n",
    "            def custom_collate_fn(batch):\n",
    "                images = []\n",
    "                cls_list = []\n",
    "                bboxes_list = []\n",
    "                batch_idx = []\n",
    "                im_files = []\n",
    "                additional_keys = {}\n",
    "                \n",
    "                for idx, item in enumerate(batch):\n",
    "                    if not isinstance(item, dict) or 'img' not in item:\n",
    "                        logging.warning(f\"Invalid batch item at index {idx}: {item}\")\n",
    "                        continue\n",
    "                    \n",
    "                    images.append(item['img'])\n",
    "                    cls = item.get('cls', torch.tensor([], dtype=torch.float32))\n",
    "                    bboxes = item.get('bboxes', torch.tensor([], dtype=torch.float32).reshape(0, 4))\n",
    "                    \n",
    "                    cls = torch.tensor(cls, dtype=torch.float32) if not isinstance(cls, torch.Tensor) else cls\n",
    "                    bboxes = torch.tensor(bboxes, dtype=torch.float32) if not isinstance(bboxes, torch.Tensor) else bboxes\n",
    "                    \n",
    "                    if cls.numel() > 0 and bboxes.numel() > 0:\n",
    "                        cls_list.append(cls)\n",
    "                        bboxes_list.append(bboxes)\n",
    "                        batch_idx.extend([idx] * cls.shape[0])\n",
    "                    \n",
    "                    im_file = item.get('im_file', '')\n",
    "                    if isinstance(im_file, str):\n",
    "                        im_files.append(im_file)\n",
    "                    else:\n",
    "                        logging.warning(f\"Invalid im_file at index {idx}: {im_file}. Using empty string.\")\n",
    "                        im_files.append('')\n",
    "                    \n",
    "                    for key, value in item.items():\n",
    "                        if key not in ['img', 'cls', 'bboxes', 'batch_idx', 'im_file']:\n",
    "                            if key not in additional_keys:\n",
    "                                additional_keys[key] = []\n",
    "                            additional_keys[key].append(value)\n",
    "                \n",
    "                if not images:\n",
    "                    logging.error(\"No valid images in batch\")\n",
    "                    raise ValueError(\"No valid images in batch\")\n",
    "                \n",
    "                images = torch.stack(images, dim=0)\n",
    "                \n",
    "                cls_tensor = torch.cat(cls_list, dim=0) if cls_list else torch.tensor([], dtype=torch.float32)\n",
    "                bboxes_tensor = torch.cat(bboxes_list, dim=0) if bboxes_list else torch.tensor([], dtype=torch.float32).reshape(0, 4)\n",
    "                batch_idx_tensor = torch.tensor(batch_idx, dtype=torch.int64) if batch_idx else torch.tensor([], dtype=torch.int64)\n",
    "                \n",
    "                batch_dict = {\n",
    "                    'img': images,\n",
    "                    'cls': cls_tensor,\n",
    "                    'bboxes': bboxes_tensor,\n",
    "                    'batch_idx': batch_idx_tensor,\n",
    "                    'im_file': im_files\n",
    "                }\n",
    "                \n",
    "                for key, values in additional_keys.items():\n",
    "                    if len(values) == len(images):\n",
    "                        try:\n",
    "                            if key == 'img_id':\n",
    "                                values = [\n",
    "                                    torch.tensor([v], dtype=torch.int64) if isinstance(v, (int, float)) or (isinstance(v, torch.Tensor) and v.numel() == 1)\n",
    "                                    else v if isinstance(v, torch.Tensor)\n",
    "                                    else torch.tensor([0], dtype=torch.int64)\n",
    "                                    for v in values\n",
    "                                ]\n",
    "                                shapes = [v.shape for v in values]\n",
    "                                if len(set(shapes)) == 1:\n",
    "                                    batch_dict[key] = torch.stack(values, dim=0)\n",
    "                                else:\n",
    "                                    max_len = max(v.numel() for v in values)\n",
    "                                    values = [\n",
    "                                        torch.cat([v, torch.zeros(max_len - v.numel(), dtype=torch.int64)]) if v.numel() < max_len\n",
    "                                        else v[:max_len]\n",
    "                                        for v in values\n",
    "                                    ]\n",
    "                                    batch_dict[key] = torch.stack(values, dim=0)\n",
    "                            elif key in ['img_shape', 'ori_shape', 'resized_shape']:\n",
    "                                values = [\n",
    "                                    torch.tensor(v, dtype=torch.int64) if isinstance(v, (tuple, list))\n",
    "                                    else v if isinstance(v, torch.Tensor)\n",
    "                                    else torch.tensor([640, 640], dtype=torch.int64)\n",
    "                                    for v in values\n",
    "                                ]\n",
    "                                shapes = [v.shape for v in values]\n",
    "                                if len(set(shapes)) == 1:\n",
    "                                    batch_dict[key] = torch.stack(values, dim=0)\n",
    "                                else:\n",
    "                                    max_len = max(v.numel() for v in values)\n",
    "                                    values = [\n",
    "                                        torch.cat([v, torch.zeros(max_len - v.numel(), dtype=torch.int64)]) if v.numel() < max_len\n",
    "                                        else v[:max_len]\n",
    "                                        for v in values\n",
    "                                    ]\n",
    "                                    batch_dict[key] = torch.stack(values, dim=0)\n",
    "                            else:\n",
    "                                if all(isinstance(v, torch.Tensor) for v in values):\n",
    "                                    shapes = [v.shape for v in values]\n",
    "                                    if len(set(shapes)) == 1:\n",
    "                                        batch_dict[key] = torch.stack(values, dim=0)\n",
    "                                    else:\n",
    "                                        max_len = max(v.numel() for v in values)\n",
    "                                        values = [\n",
    "                                            torch.cat([v, torch.zeros(max_len - v.numel(), dtype=v.dtype)]) if v.numel() < max_len\n",
    "                                            else v[:max_len]\n",
    "                                            for v in values\n",
    "                                        ]\n",
    "                                        batch_dict[key] = torch.stack(values, dim=0)\n",
    "                                elif all(isinstance(v, (int, float)) for v in values):\n",
    "                                    batch_dict[key] = torch.tensor(values, dtype=torch.int64 if all(isinstance(v, int) for v in values) else torch.float32)\n",
    "                                else:\n",
    "                                    logging.warning(f\"Skipping additional key {key}: cannot convert to tensor\")\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"Failed to process additional key {key}: {str(e)}. Skipping.\")\n",
    "                \n",
    "                return batch_dict\n",
    "    \n",
    "            # Callback to modify DataLoader after initialization\n",
    "            def on_pretrain_routine_end(trainer):\n",
    "                print(\"Entering on_pretrain_routine_end callback\")\n",
    "                logging.info(\"Entering on_pretrain_routine_end callback\")\n",
    "                try:\n",
    "                    train_dataset = trainer.train_loader.dataset\n",
    "                    # Apply targeted copy-paste to dataset labels\n",
    "                    train_dataset.labels = [targeted_copy_paste(train_dataset, labels, prob=self.hyp['copy_paste']) for labels in train_dataset.labels]\n",
    "                    # Create a new DataLoader with WeightedRandomSampler\n",
    "                    train_sampler = get_class_aware_sampler(train_dataset)\n",
    "                    new_train_loader = torch.utils.data.DataLoader(\n",
    "                        train_dataset,\n",
    "                        batch_size=self.batch_size,\n",
    "                        sampler=train_sampler,\n",
    "                        num_workers=trainer.args.workers,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                        shuffle=False  # Sampler handles shuffling\n",
    "                    )\n",
    "                    # Replace the trainer's train_loader\n",
    "                    trainer.train_loader = new_train_loader\n",
    "                    print(\"Successfully modified dataloader with class-aware sampling and targeted copy-paste\")\n",
    "                    logging.info(\"Successfully modified dataloader with class-aware sampling and targeted copy-paste\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to modify dataloader: {str(e)}\")\n",
    "                    print(f\"ERROR: Failed to modify dataloader: {str(e)}\")\n",
    "                    raise\n",
    "    \n",
    "            self.model.add_callback('on_pretrain_routine_end', on_pretrain_routine_end)\n",
    "            self.model.add_callback('on_train_epoch_end', self.on_train_epoch_end)\n",
    "    \n",
    "            g0, g1, g2 = [], [], []\n",
    "            g0_names, g1_names, g2_names = [], [], []\n",
    "    \n",
    "            all_params = [name for name, param in self.model.model.named_parameters() if param.requires_grad]\n",
    "            print(f\"Total trainable parameters: {len(all_params)}\")\n",
    "            logging.info(f\"Total trainable parameters: {len(all_params)}\")\n",
    "            bn_weight_count = sum(1 for name in all_params if 'bn' in name and '.weight' in name)\n",
    "            bn_bias_count = sum(1 for name in all_params if 'bn' in name and '.bias' in name)\n",
    "            conv_bias_count = sum(1 for name in all_params if '.bias' in name and 'bn' not in name)\n",
    "            print(f\"Expected bn.weight count: {bn_weight_count}\")\n",
    "            print(f\"Expected bn.bias count: {bn_bias_count}\")\n",
    "            print(f\"Expected conv.bias count: {conv_bias_count}\")\n",
    "            logging.info(f\"Expected bn.weight count: {bn_weight_count}\")\n",
    "            logging.info(f\"Expected bn.bias count: {bn_bias_count}\")\n",
    "            logging.info(f\"Expected conv.bias count: {conv_bias_count}\")\n",
    "    \n",
    "            for name, param in self.model.model.named_parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                if 'bn' in name and '.bias' in name:\n",
    "                    g2.append(param)\n",
    "                    g2_names.append(name)\n",
    "                elif 'bn' in name and '.weight' in name:\n",
    "                    g0.append(param)\n",
    "                    g0_names.append(name)\n",
    "                elif '.bias' in name:\n",
    "                    g0.append(param)\n",
    "                    g0_names.append(name)\n",
    "                else:\n",
    "                    g1.append(param)\n",
    "                    g1_names.append(name)\n",
    "    \n",
    "            print(f\"Created parameter groups: g0={len(g0)}, g1={len(g1)}, g2={len(g2)}\")\n",
    "            logging.info(f\"Created parameter groups: g0={len(g0)}, g1={len(g1)}, g2={len(g2)}\")\n",
    "    \n",
    "            checkpoint_param_groups = checkpoint['optimizer_state_dict']['param_groups']\n",
    "            param_groups = [\n",
    "                {'params': g0, 'lr': checkpoint_param_groups[0]['lr'], 'weight_decay': checkpoint_param_groups[0]['weight_decay']},\n",
    "                {'params': g1, 'lr': checkpoint_param_groups[1]['lr'], 'weight_decay': checkpoint_param_groups[1]['weight_decay']},\n",
    "                {'params': g2, 'lr': checkpoint_param_groups[2]['lr'], 'weight_decay': checkpoint_param_groups[2]['weight_decay']}\n",
    "            ]\n",
    "    \n",
    "            optimizer = torch.optim.AdamW(\n",
    "                param_groups,\n",
    "                betas=(0.937, 0.999)\n",
    "            )\n",
    "    \n",
    "            print(f\"Number of parameter groups in new optimizer: {len(optimizer.param_groups)}\")\n",
    "            logging.info(f\"Number of parameter groups in new optimizer: {len(optimizer.param_groups)}\")\n",
    "            print(f\"Parameters per group in new optimizer: {[len(group['params']) for group in optimizer.param_groups]}\")\n",
    "            logging.info(f\"Parameters per group in new optimizer: {[len(group['params']) for group in optimizer.param_groups]}\")\n",
    "            print(f\"Group 0 (bn weights + conv biases): {len(g0_names)} parameters\")\n",
    "            logging.info(f\"Group 0 (bn weights + conv biases): {len(g0_names)} parameters\")\n",
    "            print(f\"Group 1 (other weights): {len(g1_names)} parameters\")\n",
    "            logging.info(f\"Group 1 (other weights): {len(g1_names)} parameters\")\n",
    "            print(f\"Group 2 (bn biases): {len(g2_names)} parameters\")\n",
    "            logging.info(f\"Group 2 (bn biases): {len(g2_names)} parameters\")\n",
    "            print(f\"First 5 Group 0 parameters: {g0_names[:5]}\")\n",
    "            logging.info(f\"First 5 Group 0 parameters: {g0_names[:5]}\")\n",
    "            print(f\"First 5 Group 1 parameters: {g1_names[:5]}\")\n",
    "            logging.info(f\"First 5 Group 1 parameters: {g1_names[:5]}\")\n",
    "            print(f\"First 5 Group 2 parameters: {g2_names[:5]}\")\n",
    "            logging.info(f\"First 5 Group 2 parameters: {g2_names[:5]}\")\n",
    "    \n",
    "            try:\n",
    "                optimizer.load_state_dict(checkpoint_optimizer_state)\n",
    "                logging.info(f\"Loaded optimizer state from checkpoint\")\n",
    "                print(f\"Loaded optimizer state from checkpoint\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load optimizer state: {str(e)}\")\n",
    "                print(f\"ERROR: Failed to load optimizer state: {str(e)}\")\n",
    "                raise RuntimeError(f\"Failed to load optimizer state: {str(e)}\")\n",
    "    \n",
    "            checkpoint_lr = checkpoint_optimizer_state['param_groups'][0]['lr']\n",
    "            for group in optimizer.param_groups:\n",
    "                group['lr'] = checkpoint_lr\n",
    "                print(f\"Set lr for parameter group to {group['lr']}\")\n",
    "                logging.info(f\"Set lr for parameter group to {group['lr']}\")\n",
    "    \n",
    "            self.model.trainer = type('Trainer', (), {})()\n",
    "            self.model.trainer.optimizer = optimizer\n",
    "    \n",
    "            # Add a dummy reset method to DataLoader to avoid AttributeError\n",
    "            def dummy_reset(self):\n",
    "                pass\n",
    "            torch.utils.data.DataLoader.reset = dummy_reset\n",
    "    \n",
    "            results = self.model.train(\n",
    "                data=str(self.data_yaml),\n",
    "                epochs=remaining_epochs,\n",
    "                batch=self.batch_size,\n",
    "                imgsz=self.imgsz,\n",
    "                device=self.device,\n",
    "                project=str(self.output_dir / 'yolov8l_vehicles_custom_weights'),\n",
    "                name='check_points1',\n",
    "                exist_ok=True,\n",
    "                save=True,\n",
    "                save_period=self.save_period,\n",
    "                cache=False,\n",
    "                plots=True,\n",
    "                verbose=True,\n",
    "                pretrained=False,\n",
    "                resume=False,\n",
    "                **self.hyp\n",
    "            )\n",
    "    \n",
    "            logging.info(f\"Training loop finished. Best Score: {self.best_score:.4f}, Best Recall: {self.best_recall:.4f}\")\n",
    "            print(f\"Training loop finished. Best Score: {self.best_score:.4f}, Best Recall: {self.best_recall:.4f}\")\n",
    "            return results\n",
    "    \n",
    "        except Exception as error:\n",
    "            logging.error(f\"Training failed: {str(error)}\")\n",
    "            print(f\"ERROR: Training failed: {str(error)}\")\n",
    "            self.save_crash_checkpoint()\n",
    "            torch.cuda.empty_cache()\n",
    "            logging.info(\"Cleared CUDA cache.\")\n",
    "            print(\"Cleared CUDA cache.\")\n",
    "            raise\n",
    "\n",
    "    def evaluate(self, split='val'):\n",
    "        \"\"\"Evaluate the model on the specified split (val or test).\"\"\"\n",
    "        print(f\"Starting evaluation on '{split}' split...\")\n",
    "        logging.info(f\"Starting evaluation on '{split}' split...\")\n",
    "        try:\n",
    "            metrics = self.model.val(data=str(self.data_yaml), split=split, plots=True, conf=self.hyp.get('conf', 0.25))\n",
    "            recall = metrics.box.mr() if hasattr(metrics.box, 'mr') else metrics.box.r.mean()\n",
    "            logging.info(f\"Evaluation Metrics ({split} split): mAP50-95: {metrics.box.map:.4f}, Recall: {recall:.4f}\")\n",
    "            print(f\"Evaluation Metrics ({split} split): mAP50-95: {metrics.box.map:.4f}, Recall: {recall:.4f}\")\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Evaluation on '{split}' split failed: {str(e)}\")\n",
    "            print(f\"ERROR: Evaluation on '{split}' split failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save_final_model(self, filename=\"mostafafinal.pt\"):\n",
    "        \"\"\"Save final trained model using model.save().\"\"\"\n",
    "        print(\"Entering save_final_model\")\n",
    "        logging.info(\"Entering save_final_model\")\n",
    "        \n",
    "        if self.model is None:\n",
    "            logging.error(\"No model available to save.\")\n",
    "            print(\"ERROR: No model available to save.\")\n",
    "            return\n",
    "        if not self.weights_dir:\n",
    "            logging.error(\"Weights directory not set. Cannot save final model.\")\n",
    "            print(\"ERROR: Weights directory not set. Cannot save final model.\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            checkpoint_dir = self.weights_dir / 'check_points1'\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            final_path = checkpoint_dir / filename\n",
    "            self.model.save(str(final_path))\n",
    "            logging.info(f\"Final model saved using model.save() to {final_path}\")\n",
    "            print(f\"Final model saved using model.save() to {final_path}\")\n",
    "            self.clean_old_checkpoints()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save final model to {final_path}: {e}\")\n",
    "            print(f\"ERROR: Failed to save final model to {final_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run full training and evaluation pipeline.\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        logging.info(f\"Starting YOLOv8 Training Pipeline at {start_time}\")\n",
    "        print(f\"Starting YOLOv8 Training Pipeline at {start_time}\")\n",
    "        \n",
    "        if not self.setup():\n",
    "            logging.critical(\"Pipeline setup failed. Exiting.\")\n",
    "            print(\"CRITICAL: Pipeline setup failed. Exiting.\")\n",
    "            return\n",
    "\n",
    "        train_results = self.train()\n",
    "        \n",
    "        if train_results is not None:\n",
    "            logging.info(\"Training process completed.\")\n",
    "            print(\"Training process completed.\")\n",
    "            self.evaluate(split='val')\n",
    "            self.evaluate(split='test')\n",
    "            self.save_final_model()\n",
    "        else:\n",
    "            logging.error(\"Training process failed or was skipped.\")\n",
    "            print(\"ERROR: Training process failed or was skipped.\")\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        logging.info(f\"YOLOv8 Training Pipeline finished at {end_time}\")\n",
    "        print(f\"YOLOv8 Training Pipeline finished at {end_time}\")\n",
    "        logging.info(f\"Total execution time: {end_time - start_time}\")\n",
    "        print(f\"Total execution time: {end_time - start_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer = YOLOv8Trainer()\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T09:47:36.479696Z",
     "iopub.status.busy": "2025-05-03T09:47:36.479340Z",
     "iopub.status.idle": "2025-05-03T09:51:35.985631Z",
     "shell.execute_reply": "2025-05-03T09:51:35.984869Z",
     "shell.execute_reply.started": "2025-05-03T09:47:36.479661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 09:47:36,487 - INFO - Using device: cuda:0\n",
      "2025-05-03 09:47:36,488 - INFO - Loading hyperparameters from /kaggle/working/aug_hyp.yaml\n",
      "2025-05-03 09:47:36,492 - INFO - Loading model from /kaggle/working/runs/yolov8l_vehicles_custom_weights/check_points1/weights/best.pt\n",
      "2025-05-03 09:47:36,835 - INFO - Starting YOLOv8 Evaluation Pipeline\n",
      "2025-05-03 09:47:36,836 - INFO - Starting evaluation on 'val' split...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 112 layers, 43,609,692 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1400.5551.7 MB/s, size: 69.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/detection-cars-cleaned/val/labels.cache... 6297 images, 1 backgrounds, 0 corrupt: 100%|| 6297/6297 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 394/394 [01:49<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6297       8901      0.802      0.786      0.835      0.636\n",
      "                   car       5417       7137       0.94      0.968      0.982      0.876\n",
      "                 truck        229        290      0.746      0.745      0.789      0.563\n",
      "                   bus        611       1237      0.836      0.816      0.866      0.609\n",
      "            motorcycle        198        237      0.688      0.616      0.704      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 09:49:30,434 - INFO - Evaluation Metrics (val split): mAP50-95: 0.6360, Recall: 0.7861\n",
      "2025-05-03 09:49:30,437 - INFO - Starting evaluation on 'test' split...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (val split): mAP50-95: 0.6360, Recall: 0.7861\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 21.915.4 MB/s, size: 208.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/detection-cars-cleaned/test/labels... 6298 images, 5 backgrounds, 0 corrupt: 100%|| 6298/6298 [00:11<00:00, 533.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/detection-cars-cleaned/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 394/394 [01:50<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6298       9180      0.839      0.775      0.849      0.647\n",
      "                   car       5424       7406      0.941      0.962      0.981      0.873\n",
      "                 truck        213        290       0.76      0.659      0.764      0.568\n",
      "                   bus        644       1266      0.873      0.775       0.86      0.606\n",
      "            motorcycle        191        218      0.781      0.706      0.793      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 09:51:35,980 - INFO - Evaluation Metrics (test split): mAP50-95: 0.6468, Recall: 0.7755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (test split): mAP50-95: 0.6468, Recall: 0.7755\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "class YOLOv8Trainer:\n",
    "    def __init__(self, model_path=\"/kaggle/working/runs/yolov8l_vehicles_custom_weights/check_points1/weights/best.pt\", \n",
    "                 data_yaml=\"/kaggle/working/detection-cars-cleaned/data.yaml\"):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logging.info(f\"Using device: {self.device}\")\n",
    "        self.model_path = model_path\n",
    "        self.data_yaml = data_yaml\n",
    "        self.hyp = self.load_hyp_yaml(\"/kaggle/working/aug_hyp.yaml\")\n",
    "        self.model = self.load_model()\n",
    "\n",
    "    def load_hyp_yaml(self, hyp_path):\n",
    "        logging.info(f\"Loading hyperparameters from {hyp_path}\")\n",
    "        with open(hyp_path, 'r') as f:\n",
    "            hyp = yaml.safe_load(f)\n",
    "        return hyp\n",
    "\n",
    "    def load_model(self):\n",
    "        logging.info(f\"Loading model from {self.model_path}\")\n",
    "        model = YOLO(self.model_path)\n",
    "        model.to(self.device)\n",
    "        return model\n",
    "\n",
    "    def evaluate(self, split='val'):\n",
    "        logging.info(f\"Starting evaluation on '{split}' split...\")\n",
    "        try:\n",
    "            metrics = self.model.val(data=str(self.data_yaml), split=split, plots=True, conf=self.hyp.get('conf', 0.25))\n",
    "            recall = metrics.box.mr if hasattr(metrics.box, 'mr') else np.mean(metrics.box.r)\n",
    "            logging.info(f\"Evaluation Metrics ({split} split): mAP50-95: {metrics.box.map:.4f}, Recall: {recall:.4f}\")\n",
    "            print(f\"Evaluation Metrics ({split} split): mAP50-95: {metrics.box.map:.4f}, Recall: {recall:.4f}\")\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Evaluation on '{split}' split failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def run(self):\n",
    "        logging.info(\"Starting YOLOv8 Evaluation Pipeline\")\n",
    "        try:\n",
    "            # Skip training and go directly to evaluation\n",
    "            self.evaluate(split='val')\n",
    "            self.evaluate(split='test')\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    trainer = YOLOv8Trainer()\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7201573,
     "sourceId": 11489070,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 314566,
     "modelInstanceId": 293939,
     "sourceId": 352309,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
